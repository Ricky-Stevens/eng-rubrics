# The eng-rubrics Manifesto

## The Problem

Engineering hiring is broken.

Too often, interview decisions come down to gut feel, personal preference, and whoever speaks most confidently in the debrief. Interviewers favour different things. Opinions clash. There's no shared definition of "good"—so everyone believes they're right, and the loudest voice wins.

This creates inconsistent, unfair processes that don't reliably identify the strongest candidates. Worse, it's legally indefensible. When challenged, organisations can't point to objective criteria—only subjective impressions.

The result: the wrong people get hired, the right people get overlooked, and teams suffer.

---

## The Solution

eng-rubrics provides structured, standardised interview rubrics for assessing engineering leaders and senior individual contributors.

Each rubric is:

- **2 pages maximum** — concise enough to use, detailed enough to be rigorous
- **5 questions** — focused on track record and demonstrated experience
- **1 scorecard** — with behavioural anchors and seniority thresholds
- **Aligned to external frameworks** — not internal opinions

These rubrics don't assess technical problem-solving or culture fit. Those belong in other interview stages. eng-rubrics focuses on what's often the weakest part of the hiring process: evaluating experience, leadership, professional competence, and track record.

---

## The Principles

### 1. Experience, Not Theory

We use the STAR method (Situation, Task, Action, Result) because it tests what candidates have *actually done*—not what they *think* they'd do. If they haven't done it, they haven't done it. Track record matters.

### 2. Standards, Not Opinions

Every rubric aligns to an established, externally-owned professional framework:

- **[UK-SPEC](https://www.engc.org.uk/standards-guidance/standards/uk-spec/)** — The UK Standard for Professional Engineering Competence, maintained by the Engineering Council
- **[SFIA](https://sfia-online.org/)** — The Skills Framework for the Information Age, the global standard for digital skills

These frameworks define what "good" looks like. We reference them so interviewers aren't inventing criteria based on personal preference.

### 3. Consistency Across Interviewers

When five interviewers use the same rubric, they assess the same things in the same way. Scores become comparable. Debriefs become evidence-based. Decisions become defensible.

### 4. Seniority Through Thresholds, Not Separate Tests

Where possible, a single rubric covers multiple seniority levels through scoring thresholds. A Senior might require 20+ points; a Mid-level 15+. This reduces complexity and keeps the system usable.

### 5. Guidance, Not Automation

These rubrics inform decisions—they don't make them. The scorecard gives interviewers structured data to compare candidates fairly. The final hiring decision remains human.

---

## What This Is

- A structured first-round assessment of experience, competence, and leadership
- A tool for comparing candidates on equal terms
- A framework-aligned, legally defensible evaluation method
- A resource for technical leaders who want rigour in their hiring process

---

## What This Is Not

- **Not a technical assessment.** We don't evaluate coding ability, system design, or problem-solving. Those belong in dedicated technical rounds.
- **Not a culture fit evaluation.** Cultural alignment is important, but it's subjective and belongs elsewhere in your process.
- **Not a replacement for references.** These rubrics assess self-reported experience. Reference checks validate it.
- **Not a substitute for judgment.** The rubric provides data. You make the decision.

---

## Contributing

eng-rubrics is open source and contribution-welcome. We invite practitioners to submit rubrics for roles not yet covered, provided they:

- Follow the standard format (2 pages, 5 questions, 1 scorecard)
- Align to an established external framework (UK-SPEC, SFIA, or equivalent)
- Focus on experience and competence, not technical puzzles or culture fit
- Include behavioural anchors for scoring, not just "good/bad" labels

We won't accept contributions that:

- Replace existing framework alignments without clear justification
- Introduce subjective or opinion-based criteria
- Deviate from the core format without good reason

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## The Vision

A world where engineering hiring is consistent, fair, and evidence-based. Where candidates are assessed on track record, not charisma. Where interviewers have a shared language for what "good" means. Where organisations can defend their decisions with data.

eng-rubrics is a tool toward that world.

---

*This manifesto represents the fixed vision of eng-rubrics. The rubrics themselves will evolve; these principles won't.*
